package rtss.data.mortality.laws;

import org.apache.commons.math3.analysis.ParametricUnivariateFunction;
import org.apache.commons.math3.fitting.leastsquares.LeastSquaresBuilder;
import org.apache.commons.math3.fitting.leastsquares.LeastSquaresOptimizer;
import org.apache.commons.math3.fitting.leastsquares.LeastSquaresProblem;
import org.apache.commons.math3.fitting.leastsquares.LevenbergMarquardtOptimizer;
import org.apache.commons.math3.linear.ArrayRealVector;
import org.apache.commons.math3.linear.RealMatrix;
import org.apache.commons.math3.linear.RealVector;
import org.apache.commons.math3.optim.ConvergenceChecker;
import org.apache.commons.math3.optim.SimpleVectorValueChecker;
import org.apache.commons.math3.optim.nonlinear.vector.ModelFunction;
import org.apache.commons.math3.optim.nonlinear.vector.ModelFunctionJacobian;
import org.apache.commons.math3.optim.nonlinear.vector.jacobian.LeastSquaresBuilder;

import java.util.ArrayList;
import java.util.List;

public class HeligmanPollardFitter {

    // Define the Heligman-Pollard function
    static class HeligmanPollardFunction implements ParametricUnivariateFunction {
        @Override
        public double value(double x, double... parameters) {
            double A = parameters[0];
            double B = parameters[1];
            double C = parameters[2];
            double D = parameters[3];
            double E = parameters[4];
            double F = parameters[5];
            double G = parameters[6];
            double H = parameters[7];

            double term1 = Math.pow(A, Math.pow(x + B, C));
            double term2 = D * Math.exp(-E * Math.pow(Math.log(x) - Math.log(F), 2));
            double term3 = G * Math.pow(H, x);

            double qx = term1 + term2 + term3;
            return qx / (1 + qx); // Convert to q(x)
        }

        @Override
        public double[] gradient(double x, double... parameters) {
            // Implement the gradient if needed for optimization
            // For simplicity, we'll let the optimizer approximate the gradient
            return new double[8]; // Placeholder
        }
    }

    // Fit the Heligman-Pollard model to the binned data
    public static double[] fitHeligmanPollard(List<Bin> bins, double[] initialGuess) {
        // Check for bin consistency
        checkBinConsistency(bins);

        // Prepare the data for optimization
        int totalPoints = 0;
        for (Bin bin : bins) {
            totalPoints += 100 * bin.bin_age_width; // 100 points per year
        }

        double[] x = new double[totalPoints];
        double[] y = new double[totalPoints];

        int index = 0;
        for (Bin bin : bins) {
            double start = bin.bin_starting_age;
            double end = start + bin.bin_age_width;
            double step = 1.0 / 100; // Step size for 100 points per year

            for (double age = start; age < end; age += step) {
                x[index] = age;
                y[index] = bin.average_qx;
                index++;
            }
        }

        // Define the optimization problem
        ParametricUnivariateFunction model = new HeligmanPollardFunction();
        ModelFunction modelFunction = new ModelFunction(params -> {
            RealVector residuals = new ArrayRealVector(totalPoints);
            for (int i = 0; i < totalPoints; i++) {
                double predicted = model.value(x[i], params);
                residuals.setEntry(i, Math.abs(predicted - y[i])); // Absolute deviation
            }
            return residuals;
        });

        // Set up the optimizer
        ConvergenceChecker<LeastSquaresOptimizer.Optimum> checker =
                new SimpleVectorValueChecker(1e-6, 1e-6);
        LeastSquaresProblem problem = new LeastSquaresBuilder()
                .start(initialGuess)
                .model(modelFunction)
                .target(new ArrayRealVector(new double[totalPoints])) // Target is zero (minimize deviations)
                .maxEvaluations(1000)
                .maxIterations(1000)
                .checker(checker)
                .build();

        // Run the optimizer
        LeastSquaresOptimizer optimizer = new LevenbergMarquardtOptimizer();
        LeastSquaresOptimizer.Optimum optimum = optimizer.optimize(problem);

        // Return the fitted parameters
        return optimum.getPoint().toArray();
    }

    // Check bin consistency
    private static void checkBinConsistency(List<Bin> bins) {
        if (bins.isEmpty()) {
            throw new IllegalArgumentException("The list of bins is empty.");
        }

        double previousEnd = bins.get(0).bin_starting_age;
        for (int i = 1; i < bins.size(); i++) {
            Bin currentBin = bins.get(i);
            if (currentBin.bin_starting_age != previousEnd) {
                throw new IllegalArgumentException(
                        "Bins are not continuous. Gap between bin " + (i - 1) + " and bin " + i + "."
                );
            }
            previousEnd = currentBin.bin_starting_age + currentBin.bin_age_width;
        }
    }

    // Define the Bin structure
    static class Bin {
        double bin_starting_age;
        double bin_age_width;
        double average_qx;

        Bin(double bin_starting_age, double bin_age_width, double average_qx) {
            this.bin_starting_age = bin_starting_age;
            this.bin_age_width = bin_age_width;
            this.average_qx = average_qx;
        }
    }

    // Example usage
    public static void main(String[] args) {
        // Create some example binned data
        List<Bin> bins = new ArrayList<>();
        bins.add(new Bin(0, 1, 0.01));    // Bin 0-1 years
        bins.add(new Bin(1, 5, 0.005));   // Bin 1-6 years
        bins.add(new Bin(6, 0.5, 0.003)); // Bin 6-6.5 years

        // Provide an initial guess for the parameters A-H
        double[] initialGuess = {0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1};

        // Fit the model
        double[] fittedParameters = fitHeligmanPollard(bins, initialGuess);

        // Print the fitted parameters
        System.out.println("Fitted Parameters:");
        System.out.println("A: " + fittedParameters[0]);
        System.out.println("B: " + fittedParameters[1]);
        System.out.println("C: " + fittedParameters[2]);
        System.out.println("D: " + fittedParameters[3]);
        System.out.println("E: " + fittedParameters[4]);
        System.out.println("F: " + fittedParameters[5]);
        System.out.println("G: " + fittedParameters[6]);
        System.out.println("H: " + fittedParameters[7]);
    }
}